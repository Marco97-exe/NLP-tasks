TODO:
- F1 score masked  ✔
- test che tutto sta effettivamente facendo quello che deve ✔
- GRU al posto di LSTM ✔
- 2 layer LSTM ✔
- 2 dense layer ✔
- error analyisis (confusion matrix, grafici) ✔
- numero di parole diverse per tag / numero di occorrenze di ogni tag  ✔
- hyperparameter tuning (dropout, batch_size, lr, optimizer, regularization)
- preprocessing / oov words 
- data augmentation (tag poco comuni) / weighted loss ✔
- aumentare dimensione hidden layer ✔
- test pipeline  ✔
- mettere più commenti 
- chiedere se -LRB- e -RRB- è da togliere perchè punteggiatura ✔


PIPELINES:
    -Train Pipeline:
        -Inputs: (model, x_train, y_train, x_val, y_val, **training_info**)
            training_info -> model fit() argument information
        - History: model.fit(x_train, y_train, validation_data)
            Plots the History
        -Outputs: trained model
    
    -Predict Pipeline:
        -Inputs: (model, set_examples, prediction_info)
        -Predictions: model.predict(set_examples, **prediction_info)
        -Returns: predictions
    
    -Evaluation Pipeline:
        -Inputs: (predictions, y, metrics, metrics_names)
        -Metrics: metric_info={}
            matric_value: metric_i(y_pred=predictions, y_true=y)... forall metrics
            metric_info[metric_name]: metric_value
        -Outputs: metric_info 




SPECIFIC 
- encode df containing sentences in df of idxs ->tokenization
- implement decoder function to test that everything is ok 
- index 0 reserved 



CONDA ENV 

conda create --name nlp
conda install python=3.9
conda install -c conda-forge jupyterlab
conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch    // se avete la gpu
conda install pytorch torchvision torchaudio cpuonly -c pytorch             // se non avete la gpu
conda install pandas 
conda install -c anaconda gensim
conda install -c pytorch torchtext
conda install scikit-learn
conda install -c conda-forge tensorboard
conda install -c conda-forge matplotlib
conda install seaborn 
