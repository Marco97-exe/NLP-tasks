

TODO SPECIFIC : 
- preprocessing :
  ora la pipeline fa delle cose, ma tipo con regex e metodi di string, si potrebbe provare a fare con nltk o qualche altro tool 
  inoltre si potrebbero provare a fare altre cose più specifiche (oltre che eliminare simboli, togliere punctuation, ecc), tipo stemming, stopwords, lettere da sole, acronimi, ecc 
  bisogna in ogni caso considerare che il modello deve capire il senso della frase e deve capire le corrispondenze claim-> evidence quindi non vanno tolte cose che cambiano il senso del claim soprattutto 
  per capire cosa fare ispezionare i csv dei vari split del dataset nella cartella data 
  va comunque tutto messo nel metodo preprocessing_pipeling() e poi dopo funziona da solo basta runnare 

- preprocessing possibilities 
  lemmatization
  tony-nominated -> tony nominated or tonynominated , 64/mpeg or 64 mpeg 


TODO GENERAL : 
- rename tokenize to numberise o qualcosa di simile in as1 (tokenize non vuol dire quello) ✔
- preprocessing pipeline  ✔
- build vocab ✔
- numberise dataframe ✔
- emb matrix ✔
- dataloader ✔
- modello e architetture ✔
- train e val loop ✔
- metrics ✔
- capire se la loss iniziale ha senso ✔
- rifare train_and_eval ✔
- pulire codice (torch.isnan ecc) ✔
- capire dove perde tempo ✔
- rifare majority voting  ✔
- decidere finally il tipo di preprocessing
- essere sicuri che sta facendo tutto bene 
- scrivere bene commenti 
- decidere hyperparam 
- clean gpu before each strategy 
- trainare tutto con una strategia di sentence emb 
- applicare modifiche (regularization, dropout, altri layer, attention, bidirectional, multi_lstm)




IMPORTANT : qualsiasi tool o libreria bisogna scaricare (se decidiamo di usarla definitivamente e non solo test) va messa nel file 'env.txt' che sta fuori da entrambi gli assignments

REPORT:
- Se Learning rate troppo alto (e.g. 0.1) con Adam ad una certa uscivano solo NaN -> LR = 10^-4
- Weighted Loss perchè troppi SUPPORT nel train (classes imbalanced), quindi overfitting su quelli e poi nella validation la loss dopo un po' si impennava perchè prediva solo SUPPORT
- L2 regularization sempre per eliminare overfitting
- Provati 6 tipi di preprocessing -> scrivere risultati
- Data loaders: se MLP -> paddiamo tutti i vettori di tutti i batch alla stessa lunghezza (quella del vettore più lungo in assoluto)
                else -> paddiamo i batch in base alla lunghezza del vettore più lungo all'interno di ognuno
- nel Majority voting quando ci sono gli stessi numeri di SUPPORTS e REFUTES noi li prediciamo come REFUTES (perchè nella realtà se una frase ne ha tre che la verificano ma tre che la negano probabilmente è falsa)