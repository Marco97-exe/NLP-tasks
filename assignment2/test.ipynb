{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print all output for a cell instead of only last one \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random \n",
    "\n",
    "#pytoch imports\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([5, 6, 7]), tensor([10, 11, 12]), tensor([15, 16, 17, 18])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[3, 3, 4]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 =[torch.LongTensor([i for i in range(5*j,5*j+5-random.randint(0,2))]) for j in range(1,4)]\n",
    "#b2 =[torch.LongTensor([i for i in range(5*j,5*j+5)]) for j in range(1,4)]\n",
    "\n",
    "b1_lenghts = [len(ex) for ex in b1]\n",
    "    \n",
    "\n",
    "b1\n",
    "\n",
    "b1_lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([5, 6, 7, 0, 0, 0, 0]), tensor([10, 11, 12]), tensor([15, 16, 17, 18])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = 7\n",
    "b1[0] = nn.ConstantPad1d((0,max_tokens-b1[0].shape[0]),0)(b1[0])\n",
    "\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6,  7,  0,  0,  0,  0],\n",
       "        [10, 11, 12,  0,  0,  0,  0],\n",
       "        [15, 16, 17, 18,  0,  0,  0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_b1 = rnn.pad_sequence(b1,batch_first=True,padding_value=0)\n",
    "\n",
    "padded_b1\n",
    "padded_b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0],\n",
       " [7, 6, 6, 7],\n",
       " [1, 1, 1, 1],\n",
       " [1, 7, 5, 6],\n",
       " [7, 2, 6, 3],\n",
       " [3, 2, 5, 3],\n",
       " [2, 2, 6, 2],\n",
       " [3, 4, 2, 7],\n",
       " [1, 2, 1, 4],\n",
       " [7, 4, 3, 3],\n",
       " [5, 5, 6, 2],\n",
       " [4, 3, 2, 4],\n",
       " [3, 2, 7, 4],\n",
       " [7, 3, 2, 5],\n",
       " [1, 6, 6, 4],\n",
       " [6, 5, 5, 3],\n",
       " [2, 6, 6, 7],\n",
       " [2, 3, 1, 2],\n",
       " [5, 4, 5, 2],\n",
       " [7, 3, 3, 2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_matrix = [[random.randint(1,7) for _ in range(4)] for _ in range(19)]\n",
    "fake_matrix.insert(0,[0,0,0,0])\n",
    "fake_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_matrix = torch.Tensor(fake_matrix)   #the embedding matrix \n",
    "_ , embedding_dim = fake_matrix.shape \n",
    "emb_layer = nn.Embedding.from_pretrained(fake_matrix, freeze=False, padding_idx = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 2., 5., 3.],\n",
       "         [2., 2., 6., 2.],\n",
       "         [3., 4., 2., 7.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[5., 5., 6., 2.],\n",
       "         [4., 3., 2., 4.],\n",
       "         [3., 2., 7., 4.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[6., 5., 5., 3.],\n",
       "         [2., 6., 6., 7.],\n",
       "         [2., 3., 1., 2.],\n",
       "         [5., 4., 5., 2.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = emb_layer(padded_b1)\n",
    "\n",
    "emb.shape\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[6., 5., 5., 3.],\n",
       "        [3., 2., 5., 3.],\n",
       "        [5., 5., 6., 2.],\n",
       "        [2., 6., 6., 7.],\n",
       "        [2., 2., 6., 2.],\n",
       "        [4., 3., 2., 4.],\n",
       "        [2., 3., 1., 2.],\n",
       "        [3., 4., 2., 7.],\n",
       "        [3., 2., 7., 4.],\n",
       "        [5., 4., 5., 2.]], grad_fn=<PackPaddedSequenceBackward0>), batch_sizes=tensor([3, 3, 3, 1]), sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_embeds = pack_padded_sequence(emb,b1_lenghts,batch_first=True, enforce_sorted=False)\n",
    "\n",
    "packed_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[3., 2., 5., 3.],\n",
       "          [2., 2., 6., 2.],\n",
       "          [3., 4., 2., 7.],\n",
       "          [0., 0., 0., 0.]],\n",
       " \n",
       "         [[5., 5., 6., 2.],\n",
       "          [4., 3., 2., 4.],\n",
       "          [3., 2., 7., 4.],\n",
       "          [0., 0., 0., 0.]],\n",
       " \n",
       "         [[6., 5., 5., 3.],\n",
       "          [2., 6., 6., 7.],\n",
       "          [2., 3., 1., 2.],\n",
       "          [5., 4., 5., 2.]]], grad_fn=<IndexSelectBackward0>),\n",
       " tensor([3, 3, 4]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_padded_embeds = pad_packed_sequence(packed_embeds,batch_first=True)\n",
    "\n",
    "re_padded_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 2., 3., 0., 0., 0., 0.],\n",
       "         [2., 2., 4., 0., 0., 0., 0.],\n",
       "         [5., 6., 2., 0., 0., 0., 0.],\n",
       "         [3., 2., 7., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[5., 4., 3., 0., 0., 0., 0.],\n",
       "         [5., 3., 2., 0., 0., 0., 0.],\n",
       "         [6., 2., 7., 0., 0., 0., 0.],\n",
       "         [2., 4., 4., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[6., 2., 2., 5., 0., 0., 0.],\n",
       "         [5., 6., 3., 4., 0., 0., 0.],\n",
       "         [5., 6., 1., 5., 0., 0., 0.],\n",
       "         [3., 7., 2., 2., 0., 0., 0.]]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_reshaped = emb.permute(0,2,1)\n",
    "\n",
    "emb_reshaped.shape\n",
    "\n",
    "emb_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1214e+00],\n",
       "         [ 1.0051e+00],\n",
       "         [ 7.0928e-01],\n",
       "         [ 1.7289e+00]],\n",
       "\n",
       "        [[ 1.2594e+00],\n",
       "         [ 1.3067e+00],\n",
       "         [ 2.5334e+00],\n",
       "         [ 6.0683e-01]],\n",
       "\n",
       "        [[ 1.2158e+00],\n",
       "         [ 4.1463e-01],\n",
       "         [-7.7271e-04],\n",
       "         [-2.4944e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1214e+00,  1.0051e+00,  7.0928e-01,  1.7289e+00],\n",
       "        [ 1.2594e+00,  1.3067e+00,  2.5334e+00,  6.0683e-01],\n",
       "        [ 1.2158e+00,  4.1463e-01, -7.7271e-04, -2.4944e-01]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer = nn.Linear(max_tokens,1)\n",
    "sentence_emb = dense_layer(emb_reshaped)\n",
    "\n",
    "sentence_emb\n",
    "\n",
    "sentence_emb = sentence_emb.squeeze(2)\n",
    "\n",
    "sentence_emb\n",
    "sentence_emb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    \"\"\"\n",
    "        Class defining our model architecture  \n",
    "    \"\"\"\n",
    "    def __init__(self, emb_matrix , pad_idx: int, max_tokens: int) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_layer, self.word_embedding_dim = self.create_emb_layer(emb_matrix,pad_idx)\n",
    "\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "        self.rnn = nn.LSTM(self.word_embedding_dim, self.word_embedding_dim,bidirectional = False,batch_first = True) \n",
    "\n",
    "    def create_emb_layer(self,weights_matrix, pad_idx : int):\n",
    "        \n",
    "        matrix = torch.Tensor(weights_matrix)   #the embedding matrix \n",
    "        _ , embedding_dim = matrix.shape \n",
    "        emb_layer = nn.Embedding.from_pretrained(matrix, freeze=True, padding_idx = pad_idx)   #load pretrained weights in the layer and make it non-trainable \n",
    "        \n",
    "        return emb_layer, embedding_dim\n",
    "\n",
    "\n",
    "    def forward(self, claims, claim_lengths):\n",
    "\n",
    "        claims = claims.copy()\n",
    "        \n",
    "        claims[0] = nn.ConstantPad1d((0,max_tokens-claims[0].shape[0]),0)(claims[0])\n",
    "\n",
    "        padded_claims = rnn.pad_sequence(claims,batch_first = True, padding_value = self.pad_idx)         \n",
    "\n",
    "        embed_claims = self.embedding_layer(padded_claims)\n",
    "\n",
    "        packed_embeds = pack_padded_sequence(embed_claims, claim_lengths, batch_first=True, enforce_sorted=False)   #pack the sentences batch so that no unnecessary computation is performed for padding tokens\n",
    "        \n",
    "        packed_out, (hn,_)  = self.rnn(packed_embeds)\n",
    "\n",
    "        unpacked_out, l = pad_packed_sequence(packed_out,batch_first=True)\n",
    "\n",
    "        return unpacked_out,l \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[torch.LongTensor([i for i in range(5*j,5*j+5-random.randint(0,2))]) for j in range(1,4)]\n",
    "a_lenths = [len(ex) for ex in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([5, 6, 7, 8, 9]),\n",
       " tensor([10, 11, 12, 13, 14]),\n",
       " tensor([15, 16, 17, 18, 19])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.3150e-03,  1.1964e-01,  1.8562e-02,  1.1395e-01],\n",
       "         [-9.0859e-03,  1.6826e-01,  1.5436e-02,  1.0533e-01],\n",
       "         [-5.2416e-04,  1.0400e-01,  6.5782e-02,  1.5094e-01],\n",
       "         [-9.7087e-03,  1.4114e-01,  1.9908e-01,  2.1488e-01],\n",
       "         [-1.1714e-03,  5.5641e-02,  1.3532e-01,  4.6897e-01]],\n",
       "\n",
       "        [[-1.1281e-03,  7.7209e-02,  2.0896e-03,  2.9812e-01],\n",
       "         [-3.7012e-03,  8.2916e-02,  3.3154e-02,  3.2189e-01],\n",
       "         [-7.8853e-03,  1.3093e-01,  1.4552e-02,  8.5223e-02],\n",
       "         [-9.6754e-04,  5.0806e-02,  2.4391e-02,  3.0044e-01],\n",
       "         [-7.3871e-03,  6.7545e-02,  1.1624e-02,  2.6618e-01]],\n",
       "\n",
       "        [[-5.2273e-04,  5.5297e-02,  2.4510e-03,  3.3444e-01],\n",
       "         [-3.8958e-04,  4.1549e-02,  7.7541e-03,  1.2719e-01],\n",
       "         [-3.8990e-02,  1.0316e-01,  7.9965e-02,  3.6874e-01],\n",
       "         [-7.1470e-03,  9.4732e-02,  3.4568e-02,  3.9351e-01],\n",
       "         [-5.1282e-03,  7.7252e-02,  2.3766e-02,  4.8991e-01]]],\n",
       "       grad_fn=<IndexSelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = model(fake_matrix,0,max_tokens)\n",
    "\n",
    "p,l = m(a,a_lenths)\n",
    "\n",
    "p.shape\n",
    "\n",
    "p\n",
    "\n",
    "\n",
    "a1 = p.sum(dim=1).div(p.count_nonzero(dim=1))\n",
    "a2 = torch.sum(p,dim=1).div(1.7)\n",
    "\n",
    "a1.shape\n",
    "\n",
    "a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0046,  0.1177,  0.0868,  0.2108],\n",
       "        [-0.0042,  0.0819,  0.0172,  0.2544],\n",
       "        [-0.0104,  0.0744,  0.0297,  0.3428]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0134,  0.3463,  0.2554,  0.6200],\n",
       "        [-0.0124,  0.2408,  0.0505,  0.7481],\n",
       "        [-0.0307,  0.2188,  0.0874,  1.0081]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1\n",
    "\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0046,  0.1177,  0.0868,  0.2108, -0.0134,  0.3463,  0.2554,  0.6200],\n",
       "        [-0.0042,  0.0819,  0.0172,  0.2544, -0.0124,  0.2408,  0.0505,  0.7481],\n",
       "        [-0.0104,  0.0744,  0.0297,  0.3428, -0.0307,  0.2188,  0.0874,  1.0081]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.cat((a1,a2),dim=1)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0180,  0.4640,  0.3422,  0.8309],\n",
       "        [-0.0166,  0.3227,  0.0676,  1.0025],\n",
       "        [-0.0411,  0.2932,  0.1171,  1.3509]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = torch.stack((a1,a2), dim=0).sum(dim=0)\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0090,  0.2320,  0.1711,  0.4154],\n",
       "        [-0.0083,  0.1614,  0.0338,  0.5013],\n",
       "        [-0.0206,  0.1466,  0.0585,  0.6754]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = torch.stack((a1,a2), dim=0).mean(dim=0)\n",
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = torch.Tensor([0.7736, -0.0804,  0.0381,  0.0499])\n",
    "\n",
    "b2 = torch.Tensor([0.1595,  0.0741,  0.0667,  0.1454])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7736, -0.0804,  0.0381,  0.0499,  0.1595,  0.0741,  0.0667,  0.1454,\n",
       "         0.7736, -0.0804,  0.0381,  0.0499])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.cat((b1,b2))\n",
    "\n",
    "torch.cat((c,b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "cosine_sim = F.cosine_similarity(a1,a2)\n",
    "\n",
    "cosine_sim.shape\n",
    "\n",
    "cosine_sim = cosine_sim.unsqueeze(-1)\n",
    "\n",
    "cosine_sim.shape\n",
    "\n",
    "f = torch.cat((m1,cosine_sim),dim=1)\n",
    "\n",
    "f.shape\n",
    "\n",
    "f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Linear(9,1)\n",
    "\n",
    "labels = classifier(f)\n",
    "\n",
    "labels\n",
    "\n",
    "labels = labels.squeeze()\n",
    "\n",
    "labels \n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true = torch.Tensor([1,0,1])\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "l = loss(labels.squeeze(),true)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = [0,1,0]\n",
    "\n",
    "prova = torch.Tensor(prova)\n",
    "\n",
    "prova.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (labels>0 ).float()\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ciao(n :int):\n",
    "\n",
    "    def a():\n",
    "        print(n)\n",
    "\n",
    "    def b():\n",
    "        print(n+1)\n",
    "    \n",
    "    if n%2 == 0:\n",
    "        a()\n",
    "    else :\n",
    "        b()\n",
    "    \n",
    "\n",
    "ciao(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "#compute accuracy and f1-score \n",
    "def acc_and_f1(y_pred: torch.LongTensor, y_true: torch.LongTensor):\n",
    "    \"\"\"\n",
    "        Compute accuracy and f1-score for an epoch \n",
    "    \"\"\"\n",
    "    # correct = y_pred.eq(y_true)          \n",
    "    # acc = correct.sum()/y_true.shape[0] \n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    f1 = f1_score(y_true,y_pred,average='macro')\n",
    "\n",
    "    return acc,f1\n",
    "\n",
    "#construct y_true and y_pred lists to be passed to acc_and_f1 function, but based on majority voting strategy\n",
    "def majority_voting(y_pred,y_true,y_ids):\n",
    "    \"\"\"\n",
    "        Input: the list of predicted labels, the list of corresponing true labels, the list of claim ids to compute majority voting \n",
    "        Output : the list of predicted labels via majority voting, the list of true labels (one for each claim id)\n",
    "    \"\"\"\n",
    "    for id in y_ids:\n",
    "        mask = y_ids[y_ids == id ]\n",
    "        \n",
    "\n",
    "    return \n",
    "\n",
    "def acc_and_f1_majority(y_pred,y_true,y_ids):\n",
    "\n",
    "    y_pred,y_true = majority_voting(y_pred,y_true,y_ids)\n",
    "\n",
    "    acc, f1 = acc_and_f1(y_pred, y_true)\n",
    "\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 7])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.LongTensor([0,1,0,0,1,1,1,0,0,1,0,0,1,1,1,0,0,1,0,0,1,1,1,0])\n",
    "true = torch.LongTensor([1,0,1,0,0,1,1,1,1,0,1,0,0,1,1,1,1,0,1,0,0,1,1,1])\n",
    "ids  = torch.LongTensor([3,2,3,1,2,7,3,7,3,2,3,1,2,7,3,7,3,2,3,1,2,7,3,7])\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "ids.unique()\n",
    "\n",
    "for id in ids.unique():\n",
    "    mask = torch.isin(ids,id)\n",
    "    y_true.append(true[mask][0].item())\n",
    "    y_pred.append(torch.argmax(torch.bincount(pred[mask])).item())\n",
    "\n",
    "y_true\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16b10856870a6af5fec4ffddd4d7318a6f2add2c9f3b4bd7caecf75cea33b7bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
