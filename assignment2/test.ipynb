{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print all output for a cell instead of only last one \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random \n",
    "\n",
    "#pytoch imports\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 =[torch.LongTensor([i for i in range(5*j,5*j+5-random.randint(0,2))]) for j in range(1,4)]\n",
    "#b2 =[torch.LongTensor([i for i in range(5*j,5*j+5)]) for j in range(1,4)]\n",
    "\n",
    "b1_lenghts = [len(ex) for ex in b1]\n",
    "    \n",
    "\n",
    "b1\n",
    "\n",
    "b1_lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 7\n",
    "b1[0] = nn.ConstantPad1d((0,max_tokens-b1[0].shape[0]),0)(b1[0])\n",
    "\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_b1 = rnn.pad_sequence(b1,batch_first=True,padding_value=0)\n",
    "\n",
    "padded_b1\n",
    "padded_b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_matrix = [[random.randint(1,7) for _ in range(4)] for _ in range(19)]\n",
    "fake_matrix.insert(0,[0,0,0,0])\n",
    "fake_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_matrix = torch.Tensor(fake_matrix)   #the embedding matrix \n",
    "_ , embedding_dim = fake_matrix.shape \n",
    "emb_layer = nn.Embedding.from_pretrained(fake_matrix, freeze=False, padding_idx = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = emb_layer(padded_b1)\n",
    "\n",
    "emb.shape\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_embeds = pack_padded_sequence(emb,b1_lenghts,batch_first=True, enforce_sorted=False)\n",
    "\n",
    "packed_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_padded_embeds = pad_packed_sequence(packed_embeds,batch_first=True)\n",
    "\n",
    "re_padded_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_reshaped = emb.permute(0,2,1)\n",
    "\n",
    "emb_reshaped.shape\n",
    "\n",
    "emb_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = nn.Linear(max_tokens,1)\n",
    "sentence_emb = dense_layer(emb_reshaped)\n",
    "\n",
    "sentence_emb\n",
    "\n",
    "sentence_emb = sentence_emb.squeeze(2)\n",
    "\n",
    "sentence_emb\n",
    "sentence_emb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    \"\"\"\n",
    "        Class defining our model architecture  \n",
    "    \"\"\"\n",
    "    def __init__(self, emb_matrix , pad_idx: int, max_tokens: int) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_layer, self.word_embedding_dim = self.create_emb_layer(emb_matrix,pad_idx)\n",
    "\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "        self.rnn = nn.LSTM(self.word_embedding_dim, self.word_embedding_dim,bidirectional = False,batch_first = True) \n",
    "\n",
    "    def create_emb_layer(self,weights_matrix, pad_idx : int):\n",
    "        \n",
    "        matrix = torch.Tensor(weights_matrix)   #the embedding matrix \n",
    "        _ , embedding_dim = matrix.shape \n",
    "        emb_layer = nn.Embedding.from_pretrained(matrix, freeze=True, padding_idx = pad_idx)   #load pretrained weights in the layer and make it non-trainable \n",
    "        \n",
    "        return emb_layer, embedding_dim\n",
    "\n",
    "\n",
    "    def forward(self, claims, claim_lengths):\n",
    "\n",
    "        claims = claims.copy()\n",
    "        \n",
    "        claims[0] = nn.ConstantPad1d((0,max_tokens-claims[0].shape[0]),0)(claims[0])\n",
    "\n",
    "        padded_claims = rnn.pad_sequence(claims,batch_first = True, padding_value = self.pad_idx)         \n",
    "\n",
    "        embed_claims = self.embedding_layer(padded_claims)\n",
    "\n",
    "        packed_embeds = pack_padded_sequence(embed_claims, claim_lengths, batch_first=True, enforce_sorted=False)   #pack the sentences batch so that no unnecessary computation is performed for padding tokens\n",
    "        \n",
    "        packed_out, (hn,_)  = self.rnn(packed_embeds)\n",
    "\n",
    "        unpacked_out, l = pad_packed_sequence(packed_out,batch_first=True)\n",
    "\n",
    "        return unpacked_out,l \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[torch.LongTensor([i for i in range(5*j,5*j+5-random.randint(0,2))]) for j in range(1,4)]\n",
    "a_lenths = [len(ex) for ex in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model(fake_matrix,0,max_tokens)\n",
    "\n",
    "p,l = m(a,a_lenths)\n",
    "\n",
    "p.shape\n",
    "\n",
    "p\n",
    "\n",
    "\n",
    "a1 = p.sum(dim=1).div(p.count_nonzero(dim=1))\n",
    "a2 = torch.sum(p,dim=1).div(1.7)\n",
    "\n",
    "a1.shape\n",
    "\n",
    "a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1\n",
    "\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.cat((a1,a2),dim=1)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = torch.stack((a1,a2), dim=0).sum(dim=0)\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = torch.stack((a1,a2), dim=0).mean(dim=0)\n",
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = torch.Tensor([0.7736, -0.0804,  0.0381,  0.0499])\n",
    "\n",
    "b2 = torch.Tensor([0.1595,  0.0741,  0.0667,  0.1454])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat((b1,b2))\n",
    "\n",
    "torch.cat((c,b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "cosine_sim = F.cosine_similarity(a1,a2)\n",
    "\n",
    "cosine_sim.shape\n",
    "\n",
    "cosine_sim = cosine_sim.unsqueeze(-1)\n",
    "\n",
    "cosine_sim.shape\n",
    "\n",
    "f = torch.cat((m1,cosine_sim),dim=1)\n",
    "\n",
    "f.shape\n",
    "\n",
    "f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Linear(9,1)\n",
    "\n",
    "labels = classifier(f)\n",
    "\n",
    "labels\n",
    "\n",
    "labels = labels.squeeze()\n",
    "\n",
    "labels \n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true = torch.Tensor([1,0,1])\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "l = loss(labels.squeeze(),true)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = [0,1,0]\n",
    "\n",
    "prova = torch.Tensor(prova)\n",
    "\n",
    "prova.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (labels>0 ).float()\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ciao(n :int):\n",
    "\n",
    "    def a():\n",
    "        print(n)\n",
    "\n",
    "    def b():\n",
    "        print(n+1)\n",
    "    \n",
    "    if n%2 == 0:\n",
    "        a()\n",
    "    else :\n",
    "        b()\n",
    "    \n",
    "\n",
    "ciao(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "#compute accuracy and f1-score \n",
    "def acc_and_f1(y_pred: torch.LongTensor, y_true: torch.LongTensor):\n",
    "    \"\"\"\n",
    "        Compute accuracy and f1-score for an epoch \n",
    "    \"\"\"\n",
    "    # correct = y_pred.eq(y_true)          \n",
    "    # acc = correct.sum()/y_true.shape[0] \n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    f1 = f1_score(y_true,y_pred,average='macro')\n",
    "\n",
    "    return acc,f1\n",
    "\n",
    "#construct y_true and y_pred lists to be passed to acc_and_f1 function, but based on majority voting strategy\n",
    "def majority_voting(y_pred,y_true,y_ids):\n",
    "    \"\"\"\n",
    "        Input: the list of predicted labels, the list of corresponing true labels, the list of claim ids to compute majority voting \n",
    "        Output : the list of predicted labels via majority voting, the list of true labels (one for each claim id)\n",
    "    \"\"\"\n",
    "    for id in y_ids:\n",
    "        mask = y_ids[y_ids == id ]\n",
    "        \n",
    "\n",
    "    return \n",
    "\n",
    "def acc_and_f1_majority(y_pred,y_true,y_ids):\n",
    "\n",
    "    y_pred,y_true = majority_voting(y_pred,y_true,y_ids)\n",
    "\n",
    "    acc, f1 = acc_and_f1(y_pred, y_true)\n",
    "\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.LongTensor([0,1,0,0,1,1,1,0,0,1,0,0,1,1,1,0,0,1,0,0,1,1,1,0])\n",
    "true = torch.LongTensor([1,0,1,0,0,1,1,1,1,0,1,0,0,1,1,1,1,0,1,0,0,1,1,1])\n",
    "ids  = torch.LongTensor([3,2,3,1,2,7,3,7,3,2,3,1,2,7,3,7,3,2,3,1,2,7,3,7])\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "ids.unique()\n",
    "\n",
    "for id in ids.unique():\n",
    "    mask = torch.isin(ids,id)\n",
    "    y_true.append(true[mask][0].item())\n",
    "    y_pred.append(torch.argmax(torch.bincount(pred[mask])).item())\n",
    "\n",
    "y_true\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16b10856870a6af5fec4ffddd4d7318a6f2add2c9f3b4bd7caecf75cea33b7bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
